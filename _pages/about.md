---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


**ğŸ‘ï¸Vision is the interface where photons meet consciousness - for carbon and silicon alike.**  


Hi ğŸ‘‹! Iâ€™m a CS Ph.D. candidate at UCD in the Vision and Analytics Lab (<a href="https://soumyabrata.dev/theia/">THEIA Lab</a>), working with Prof. <a href="https://soumyabrata.dev/">Soumyabrata Dev</a>.  

I previously served as a research assistant at <a href="http://english.siat.cas.cn/">SIAT</a>, collaborating with Prof. <a href="https://scholar.google.com/citations?user=LggfIykAAAAJ&hl=en">Zhengkun Yi</a>, and earned my M.S. degree in Computer Science from <a href="https://www.usm.my/en/">USM</a> under the supervision of Prof. <a href="https://scholar.google.com/citations?user=OehI3nsAAAAJ&hl=en">Putra Sumari</a>.  


My current research focuses on computer vision, machine learning, and AI.  

<!--I have published several papers with total <a href='https://scholar.google.com/citations?user=WsVak2gAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a> google scholar citations. 
-->

<br>


# ğŸ”¥ News
- *2025.09*: &nbsp;ğŸ“ Three new papers on arXiv: [MoCLIP-Lite](https://arxiv.org/abs/2509.17084) [[Code]](https://github.com/microa/MoCLIP-Lite), [MVP](https://arxiv.org/abs/2509.18388) [[Code]](https://github.com/microa/MVP), [MoCrop](https://arxiv.org/abs/2509.18473) [[Code]](https://github.com/microa/MoCrop)
- *2025.02*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: LLM Agents from **UC Berkeley**!
- *2024.11*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: Neural Network and Deep Learning from DeepLearning.AI!
- *2024.09*: &nbsp;ğŸ† Ranked top2.5%<!--13/523--> at National Information Center: Video Recognition for City Management Competition!
- *2024.08*: &nbsp;ğŸ† Ranked top3.5%<!--38/1066--> at **NVIDIA** and **Alibaba**: Multimodal Large Model Data Synthesis Challenge!
- *2024.07*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: Visual Perception from **Columbia University**!


# ğŸ“ Publications 

- [MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors](https://arxiv.org/abs/2509.17084), **B. Huang**, N. Wang, A. Parakash, S. Dev arXiv preprint [2025] [[Code]](https://github.com/microa/MoCLIP-Lite)
- [MVP: Motion Vector Propagation for Zero-Shot Video Object Detection](https://arxiv.org/abs/2509.18388), **B. Huang**, N. Wang, W. Yao, S. Dev arXiv preprint [2025] [[Code]](https://github.com/microa/MVP)
- [MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition](https://arxiv.org/abs/2509.18473), **B. Huang**, W. Yao, S. Chen, G. Wang, Q. Wang, S. Dev arXiv preprint [2025] [[Code]](https://github.com/microa/MoCrop)
- [Optimal Brain Connection: Towards Efficient Structural Pruning](https://arxiv.org/abs/2508.05521), S. Chen, W. Ma, **B. Huang**, Q. Wang, G. Wang, W. Sun, L. Huang, D. John arXiv preprint [2025]
- [DCentNet: Decentralized multistage biomedical signal classification using early exits](https://doi.org/10.1016/j.bspc.2024.107468  ), X. Li, **B. Huang**, B. Cardiff, D. John Biomedical Signal Processing and Control [2025]
- [Dynamic liquid volume estimation using optical tactile sensors and spiking neural network](https://doi.org/10.1007/s11370-023-00488-0  ), **B. Huang**, S. Fang, M. Yin et al. Springer - Intelligent Service Robotics [2024]

- More papers on [Google Scholar](https://scholar.google.com/citations?user=WsVak2gAAAAJ).

# ğŸ‘¨â€ğŸ’» Service
- Reviewer - AAAI, ACM MM, ICRA, IEEE T-ASE, IEEE TIM
- Session Assistant - IEEE RCAR

# ğŸ‘¨â€ğŸ’» Research Focuses
<pre>
 â€¢ VLM, MLLM, World Models     (Outputs)       2025.08 - present
 â€¢ Video Recognition           (Outputs)       2024.07 - present
 â€¢ Model Compression           (<a href="https://github.com/microa/DSCEE">Outputs</a>)       2023.09 - 2024.06
 â€¢ Embodied Intelligence       (<a href="https://github.com/microa/Robotics">Outputs</a>)       2021.08 - 2023.08
 â€¢ Embedded Systems            (<a href="https://github.com/microa/Embedded_Projects">Outputs</a>)        prior  - 2021
</pre>

# ğŸƒâ€â™‚ï¸ Personal life
- ğŸƒâ€â™‚ï¸ Completed two marathons (42.195 km)
<br>
