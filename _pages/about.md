---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


**ğŸ‘ï¸Vision is the interface where photons meet consciousness - for carbon and silicon alike.**  


Hi ğŸ‘‹! Iâ€™m a CS Ph.D. candidate at <a href="https://www.ucd.ie/">UCD</a> in the Vision and Analytics Lab (<a href="https://soumyabrata.dev/theia/">THEIA Lab</a>), working with Prof. <a href="https://soumyabrata.dev/">Soumyabrata Dev</a>.  

I previously served as a research assistant at <a href="https://www.siat.ac.cn/">SIAT</a>, <a href="https://english.cas.cn/">CAS</a>. collaborating with Prof. <a href="https://scholar.google.com/citations?user=LggfIykAAAAJ&hl=en">Zhengkun Yi</a>, and earned my M.S. degree in Computer Science from <a href="https://www.usm.my/en/">USM</a> under the supervision of Prof. <a href="https://scholar.google.com/citations?user=OehI3nsAAAAJ&hl=en">Putra Sumari</a>.  


My current research focuses on computer vision, machine learning, and AI.  

<!--I have published several papers with total <a href='https://scholar.google.com/citations?user=WsVak2gAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a> google scholar citations. 
-->

<br>


# ğŸ”¥ News
- *2025.12*: &nbsp;ğŸ‘¨â€ğŸ’» Joined an AI startup as an AI Algorithm Engineer (Intern)
- *2025.10*: &nbsp;ğŸ¤ Contributed **MV-Only** (high-speed mode) to **mv-extractor**. [[upstream]](https://github.com/LukasBommes/mv-extractor) [[my fork]](https://github.com/microa/hs-mv-extractor) [[PyPI]](https://pypi.org/project/motion-vector-extractor/)
- *2025.09*: &nbsp;ğŸ“ Preprinted MoCLIP-Lite on arXiv: [paper](https://arxiv.org/abs/2509.17084) [[code]](https://github.com/microa/MoCLIP-Lite)
- *2025.09*: &nbsp;ğŸ“ Preprinted MVP on arXiv: [paper](https://arxiv.org/abs/2509.18388) [[code]](https://github.com/microa/MVP)
- *2025.09*: &nbsp;ğŸ“ Preprinted MoCrop on arXiv: [paper](https://arxiv.org/abs/2509.18473) [[code]](https://github.com/microa/MoCrop)
- *2025.07*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: Deep Learning with PyTorch : Image Segmentation from Coursera!
- *2025.02*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: LLM Agents from **UC Berkeley**!
- *2024.11*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: Neural Network and Deep Learning from DeepLearning.AI!
- *2024.09*: &nbsp;ğŸ† Ranked top2.5%<!--13/523--> at National Information Center: Video Recognition for City Management Competition!
- *2024.08*: &nbsp;ğŸ† Ranked top3.5%<!--38/1066--> at **NVIDIA** and **Alibaba**: Multimodal Large Model Data Synthesis Challenge!
- *2024.07*: &nbsp;ğŸ‘¨â€ğŸ“ Obtained a new certification: Visual Perception from **Columbia University**!


# ğŸ“ Latest Publications 

**2025**
- **MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors**  
  **B. Huang**, N. Wang, A. Parakash, S. Dev  
  arXiv preprint [2025] [[Paper]](https://arxiv.org/abs/2509.17084) [[Code]](https://github.com/microa/MoCLIP-Lite)

- **MVP: Motion Vector Propagation for Zero-Shot Video Object Detection**  
  **B. Huang**, N. Wang, W. Yao, S. Dev  
  arXiv preprint [2025] [[Paper]](https://arxiv.org/abs/2509.18388) [[Code]](https://github.com/microa/MVP)

- **MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition**  
  **B. Huang**, W. Yao, S. Chen, G. Wang, Q. Wang, S. Dev  
  arXiv preprint [2025] [[Paper]](https://arxiv.org/abs/2509.18473) [[Code]](https://github.com/microa/MoCrop)

- **TinyDrop: Tiny Model Guided Token Dropping for Vision Transformers**  
  G. Wang, Q. Wang, **B. Huang**, S. Chen, D. John  
  arXiv preprint [2025] [[Paper]](https://arxiv.org/abs/2509.03379)

- **Optimal Brain Connection: Towards Efficient Structural Pruning**  
  S. Chen, W. Ma, **B. Huang**, Q. Wang, G. Wang, W. Sun, L. Huang, D. John  
  arXiv preprint [2025] [[Paper]](https://arxiv.org/abs/2508.05521)

- **DCentNet: Decentralized multistage biomedical signal classification using early exits**  
  X. Li, **B. Huang**, B. Cardiff, D. John  
  Biomedical Signal Processing and Control [2025] [[Paper]](https://doi.org/10.1016/j.bspc.2024.107468) [[Code]](https://github.com/microa/DSCEE)

**2024**
- **Dynamic liquid volume estimation using optical tactile sensors and spiking neural network**  
  **B. Huang**, S. Fang, M. Yin et al.  
  Springer - Intelligent Service Robotics [2024] [[Paper]](https://doi.org/10.1007/s11370-023-00488-0)

- More papers on [Google Scholar](https://scholar.google.com/citations?user=WsVak2gAAAAJ).

# ğŸ§© Open-Source Contributions
- **mv-extractor** â€” Contributor (2025)  
  A fast H.264/MPEG-4 motion-vector extractor with optional RGB decode skipping.  
  â€¢ Key: Implemented **Motion-Vectors-Only** / frame-decode skipping mode; docs & tests; acknowledged upstream.  
  â€¢ Links: [Upstream](https://github.com/LukasBommes/mv-extractor) Â· [My fork](https://github.com/microa/hs-mv-extractor) Â· [PyPI](https://pypi.org/project/motion-vector-extractor/)  
  <a href="https://github.com/LukasBommes/mv-extractor"><img alt="GitHub stars" src="https://img.shields.io/github/stars/LukasBommes/mv-extractor?style=social"></a>
  <a href="https://pypi.org/project/motion-vector-extractor/"><img alt="PyPI" src="https://img.shields.io/pypi/v/motion-vector-extractor"></a>


# ğŸ‘¨â€ğŸ’» Service
- Reviewer - AAAI, ACM MM, IEEE ICRA, IEEE ICASSP, IEEE TIP, IEEE T-ASE, IEEE TIM
- Session Assistant - IEEE RCAR



# ğŸ‘¨â€ğŸ’» Research Focuses
<pre>
 â€¢ AIGC                        (Outputs)       2025 - present
 â€¢ Video Recognition           (<a href="/video-recognition/">Outputs</a>)       2025 - present
 â€¢ Model Compression           (<a href="/model-compression/">Outputs</a>)       2023 - 2025
 â€¢ Embodied Intelligence       (<a href="/robotics/">Outputs</a>)       2021 - 2023

</pre>

# ğŸƒâ€â™‚ï¸ Personal life
- ğŸƒâ€â™‚ï¸ Completed two marathons (42.195 km)
<br>
